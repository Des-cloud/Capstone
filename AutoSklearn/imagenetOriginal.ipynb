{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00afc1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a054712",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = load_dataset(\n",
    "    'imagenet-1k',\n",
    "    split='train',\n",
    "    use_auth_token=True,\n",
    "    cache_dir=\"/scratch/doa240/.cache/huggingface/datasets\",\n",
    "    streaming=True,\n",
    "    ignore_verifications=True  # set to True if seeing splits Error\n",
    ")\n",
    "trainData = trainData.shuffle(seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb21e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "i = 1\n",
    "for data in trainData:\n",
    "    img = data['image']\n",
    "    img = img.resize((224,224))\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    if(len(X_train) > 0 and img.shape != X_train[-1].shape):\n",
    "        print(i, \"wrong\", img.shape, X_train[-1].shape)\n",
    "        break\n",
    "    X_train.append(img)\n",
    "    y_train.append(data['label'])\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    if i == 150000:\n",
    "        break\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefaf547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 50176)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(X_train)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80984dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fb1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import autosklearn.metrics\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "from smac.tae import StatusType \n",
    "from sklearn.metrics import accuracy_score, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b407e209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-04-04 02:28:42,376:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 02:34:17,038:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 02:39:40,226:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 02:42:25,858:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 02:44:17,527:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 02:55:34,791:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 03:10:46,052:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-04 05:00:27,152:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:23:06,537:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:28:52,411:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:33:09,135:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:42:16,728:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:42:34,848:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:42:53,772:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:48:11,972:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:52:03,767:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 06:55:20,521:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 07:00:08,296:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 07:10:30,599:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n",
      "[WARNING] [2023-04-04 07:22:58,720:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n",
      "\tModels besides current dummy model: 0\n",
      "\tDummy models: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_class=<class 'autosklearn.ensembles.ensemble_selection.EnsembleSelection'>,\n",
       "                      memory_limit=307200, n_jobs=-1,\n",
       "                      per_run_time_limit=14400.0, seed=101,\n",
       "                      time_left_for_this_task=86400)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=(3600*24), \n",
    "    per_run_time_limit = (3600*24)/6,\n",
    "    seed=101,\n",
    "    n_jobs=-1,\n",
    "    memory_limit= 3072*100\n",
    ")\n",
    "automl.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6f1026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('auto-sklearn results:\\n'\n",
      " '  Dataset name: 14a0a2ba-d269-11ed-8a71-00110a6b78e8\\n'\n",
      " '  Metric: accuracy\\n'\n",
      " '  Best validation score: 0.011455\\n'\n",
      " '  Number of target algorithm runs: 158\\n'\n",
      " '  Number of successful target algorithm runs: 43\\n'\n",
      " '  Number of crashed target algorithm runs: 49\\n'\n",
      " '  Number of target algorithms that exceeded the time limit: 61\\n'\n",
      " '  Number of target algorithms that exceeded the memory limit: 5\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(automl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239bbaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rank  ensemble_weight type      cost      duration\n",
      "model_id                                                    \n",
      "131          1             0.02  lda  0.988545  11277.734571\n",
      "133          2             0.02  lda  0.988788   2839.181123\n",
      "126          3             0.02  lda  0.988808   2816.876561\n",
      "122          4             0.02  lda  0.988929   2565.308329\n",
      "149          5             0.02  lda  0.989293   4303.493482\n",
      "123          6             0.04  lda  0.990081   2428.859432\n",
      "148          7             0.04  lda  0.990263   2780.847593\n",
      "143          8             0.04  lda  0.990667   2856.428433\n",
      "140          9             0.02  lda  0.991717   3803.959288\n",
      "66          10             0.02  lda  0.991818   3449.527500\n",
      "110         11             0.02  lda  0.991919   2850.401667\n",
      "43          12             0.02  lda  0.992000   3489.962146\n",
      "107         13             0.02  lda  0.992081   3087.108957\n",
      "61          14             0.02  lda  0.992141   3226.186872\n",
      "71          15             0.02  lda  0.992283   1971.300244\n",
      "91          16             0.02  lda  0.992747   2009.095011\n",
      "39          17             0.02  lda  0.992788  11351.325563\n",
      "94          18             0.04  lda  0.993333   3458.629469\n",
      "108         19             0.02  lda  0.993616   3086.100940\n",
      "84          20             0.20  lda  0.994222   1440.769546\n",
      "45          21             0.06  lda  0.998909   3803.719567\n",
      "103         22             0.02  lda  0.998929   3322.782538\n",
      "114         23             0.26  lda  0.998929   1499.963808\n"
     ]
    }
   ],
   "source": [
    "print(automl.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5e6230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{39: {'model_id': 39, 'rank': 1, 'cost': 0.9927878787878788, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1550ea416700>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155312b468e0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1551433ffac0>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.0004558809131391089)}, 43: {'model_id': 43, 'rank': 2, 'cost': 0.992, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155312205370>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155312e9ce20>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155312e9ca60>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=4.632968970453719e-05)}, 45: {'model_id': 45, 'rank': 3, 'cost': 0.9989090909090909, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155501845070>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155313825ac0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155313825550>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.062012616923110234)}, 61: {'model_id': 61, 'rank': 4, 'cost': 0.9921414141414141, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x15531068da30>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553128ac070>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x15531372b370>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.0065246532131708924)}, 66: {'model_id': 66, 'rank': 5, 'cost': 0.9918181818181818, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1551435335e0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553127a7cd0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x15531260f4c0>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.0065246532131708924)}, 71: {'model_id': 71, 'rank': 6, 'cost': 0.9922828282828283, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155501774970>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155112408610>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1553122b4820>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.0002516859996729011)}, 84: {'model_id': 84, 'rank': 7, 'cost': 0.9942222222222222, 'ensemble_weight': 0.2, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x15550179b6a0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155313a9a7f0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155313aba160>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.00024255566698616206)}, 91: {'model_id': 91, 'rank': 8, 'cost': 0.9927474747474747, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155312257be0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1554ff6fdb80>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1554ff6fd520>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.08586791857726132)}, 94: {'model_id': 94, 'rank': 9, 'cost': 0.9933333333333333, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155312eed970>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553133b3970>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1553133b3c10>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=1.134606806388303e-05)}, 103: {'model_id': 103, 'rank': 10, 'cost': 0.9989292929292929, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x15531394a130>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155313195df0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155313195280>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.0005190218061329473)}, 107: {'model_id': 107, 'rank': 11, 'cost': 0.9920808080808081, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155312708af0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x15531360cd90>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x15531360c790>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.0008015444704082174)}, 108: {'model_id': 108, 'rank': 12, 'cost': 0.9936161616161616, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1553101467f0>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1550f0748220>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155312d51d60>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.004283452328300061)}, 110: {'model_id': 110, 'rank': 13, 'cost': 0.9919191919191919, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1553125ee6a0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x15531308ec70>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x15531308e130>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=0.04803835377101455)}, 114: {'model_id': 114, 'rank': 14, 'cost': 0.9989292929292929, 'ensemble_weight': 0.26, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x15531360cc10>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553125ac370>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1550ea42f220>, 'sklearn_classifier': LinearDiscriminantAnalysis(tol=1.4028053516157765e-05)}, 122: {'model_id': 122, 'rank': 15, 'cost': 0.9889292929292929, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1555017de190>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155313769040>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155313769880>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.01855750021835513)}, 123: {'model_id': 123, 'rank': 16, 'cost': 0.9900808080808081, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155312fcfac0>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553105744f0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1553105744c0>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.015292986136222023)}, 126: {'model_id': 126, 'rank': 17, 'cost': 0.9888080808080808, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1550ea42f9a0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x15531059b640>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x15531059bbb0>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.5405297161990744, solver='lsqr',\n",
      "                           tol=0.027812066925373625)}, 131: {'model_id': 131, 'rank': 18, 'cost': 0.9885454545454545, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1553137692e0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155310cadf40>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155310cade20>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3637649179398811, solver='lsqr',\n",
      "                           tol=1.3772748978063219e-05)}, 133: {'model_id': 133, 'rank': 19, 'cost': 0.9887878787878788, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155310574190>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553138a1100>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1553138a12b0>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.4771526021747868, solver='lsqr',\n",
      "                           tol=0.012243686657732018)}, 140: {'model_id': 140, 'rank': 20, 'cost': 0.9917171717171717, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x15531059b790>, 'balancing': Balancing(random_state=101), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x15514334ca30>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x15514334cbe0>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.5, solver='lsqr',\n",
      "                           tol=0.01455533901979706)}, 143: {'model_id': 143, 'rank': 21, 'cost': 0.9906666666666667, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x155310cadb20>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553124d7fa0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1553124d7730>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.5, solver='lsqr',\n",
      "                           tol=0.02849806568634054)}, 148: {'model_id': 148, 'rank': 22, 'cost': 0.9902626262626263, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x1550ea35b640>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x1553124e5ca0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x1553124e5b50>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.5693054093855903, solver='lsqr',\n",
      "                           tol=0.06060880957872665)}, 149: {'model_id': 149, 'rank': 23, 'cost': 0.9892929292929293, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x15514334c5e0>, 'balancing': Balancing(random_state=101, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x155312ee5d00>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x155312ee5af0>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.02049801727759781)}}\n"
     ]
    }
   ],
   "source": [
    "print(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674ffa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagenetOriginal.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(automl, \"imagenetOriginal.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c02648",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = load_dataset(\n",
    "    'imagenet-1k',\n",
    "    split='validation',\n",
    "    use_auth_token=True,\n",
    "    cache_dir=\"/scratch/doa240/.cache/huggingface/datasets\",\n",
    "    streaming=True,\n",
    "    ignore_verifications=True  # set to True if seeing splits Error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab0014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for data in testData:\n",
    "    img = data['image']\n",
    "    img = img.resize((224,224))\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    X_test.append(img)\n",
    "    y_test.append(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8e7e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 50176)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f816654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "312c08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.01204\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "pred = automl.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, pred)\n",
    "print(\"Test Accuracy score {0}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb0d24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0 0.02\n",
      "Label: 1 0.0\n",
      "Label: 2 0.02\n",
      "Label: 3 0.02\n",
      "Label: 4 0.06\n",
      "Label: 5 0.0\n",
      "Label: 6 0.06\n",
      "Label: 7 0.0\n",
      "Label: 8 0.02\n",
      "Label: 9 0.0\n",
      "Label: 10 0.0\n",
      "Label: 11 0.0\n",
      "Label: 12 0.0\n",
      "Label: 13 0.02\n",
      "Label: 14 0.0\n",
      "Label: 15 0.0\n",
      "Label: 16 0.0\n",
      "Label: 17 0.0\n",
      "Label: 18 0.0\n",
      "Label: 19 0.0\n",
      "Label: 20 0.0\n",
      "Label: 21 0.0\n",
      "Label: 22 0.02\n",
      "Label: 23 0.0\n",
      "Label: 24 0.0\n",
      "Label: 25 0.0\n",
      "Label: 26 0.0\n",
      "Label: 27 0.0\n",
      "Label: 28 0.0\n",
      "Label: 29 0.04\n",
      "Label: 30 0.0\n",
      "Label: 31 0.02\n",
      "Label: 32 0.0\n",
      "Label: 33 0.0\n",
      "Label: 34 0.06\n",
      "Label: 35 0.0\n",
      "Label: 36 0.0\n",
      "Label: 37 0.0\n",
      "Label: 38 0.0\n",
      "Label: 39 0.0\n",
      "Label: 40 0.0\n",
      "Label: 41 0.0\n",
      "Label: 42 0.0\n",
      "Label: 43 0.0\n",
      "Label: 44 0.0\n",
      "Label: 45 0.0\n",
      "Label: 46 0.0\n",
      "Label: 47 0.0\n",
      "Label: 48 0.0\n",
      "Label: 49 0.0\n",
      "Label: 50 0.0\n",
      "Label: 51 0.0\n",
      "Label: 52 0.0\n",
      "Label: 53 0.0\n",
      "Label: 54 0.0\n",
      "Label: 55 0.0\n",
      "Label: 56 0.0\n",
      "Label: 57 0.02\n",
      "Label: 58 0.0\n",
      "Label: 59 0.0\n",
      "Label: 60 0.0\n",
      "Label: 61 0.0\n",
      "Label: 62 0.0\n",
      "Label: 63 0.0\n",
      "Label: 64 0.0\n",
      "Label: 65 0.0\n",
      "Label: 66 0.0\n",
      "Label: 67 0.0\n",
      "Label: 68 0.02\n",
      "Label: 69 0.0\n",
      "Label: 70 0.0\n",
      "Label: 71 0.0\n",
      "Label: 72 0.0\n",
      "Label: 73 0.0\n",
      "Label: 74 0.0\n",
      "Label: 75 0.06\n",
      "Label: 76 0.0\n",
      "Label: 77 0.0\n",
      "Label: 78 0.16\n",
      "Label: 79 0.0\n",
      "Label: 80 0.08\n",
      "Label: 81 0.0\n",
      "Label: 82 0.0\n",
      "Label: 83 0.0\n",
      "Label: 84 0.0\n",
      "Label: 85 0.0\n",
      "Label: 86 0.0\n",
      "Label: 87 0.0\n",
      "Label: 88 0.0\n",
      "Label: 89 0.0\n",
      "Label: 90 0.0\n",
      "Label: 91 0.02\n",
      "Label: 92 0.04\n",
      "Label: 93 0.0\n",
      "Label: 94 0.0\n",
      "Label: 95 0.02\n",
      "Label: 96 0.0\n",
      "Label: 97 0.0\n",
      "Label: 98 0.0\n",
      "Label: 99 0.0\n",
      "Label: 100 0.02\n",
      "Label: 101 0.0\n",
      "Label: 102 0.02\n",
      "Label: 103 0.0\n",
      "Label: 104 0.0\n",
      "Label: 105 0.0\n",
      "Label: 106 0.02\n",
      "Label: 107 0.06\n",
      "Label: 108 0.0\n",
      "Label: 109 0.0\n",
      "Label: 110 0.0\n",
      "Label: 111 0.0\n",
      "Label: 112 0.02\n",
      "Label: 113 0.0\n",
      "Label: 114 0.0\n",
      "Label: 115 0.02\n",
      "Label: 116 0.0\n",
      "Label: 117 0.0\n",
      "Label: 118 0.0\n",
      "Label: 119 0.0\n",
      "Label: 120 0.0\n",
      "Label: 121 0.0\n",
      "Label: 122 0.0\n",
      "Label: 123 0.0\n",
      "Label: 124 0.0\n",
      "Label: 125 0.0\n",
      "Label: 126 0.0\n",
      "Label: 127 0.0\n",
      "Label: 128 0.0\n",
      "Label: 129 0.02\n",
      "Label: 130 0.02\n",
      "Label: 131 0.0\n",
      "Label: 132 0.0\n",
      "Label: 133 0.0\n",
      "Label: 134 0.0\n",
      "Label: 135 0.0\n",
      "Label: 136 0.0\n",
      "Label: 137 0.0\n",
      "Label: 138 0.06\n",
      "Label: 139 0.06\n",
      "Label: 140 0.0\n",
      "Label: 141 0.08\n",
      "Label: 142 0.22\n",
      "Label: 143 0.02\n",
      "Label: 144 0.0\n",
      "Label: 145 0.0\n",
      "Label: 146 0.0\n",
      "Label: 147 0.04\n",
      "Label: 148 0.0\n",
      "Label: 149 0.02\n",
      "Label: 150 0.0\n",
      "Label: 151 0.0\n",
      "Label: 152 0.0\n",
      "Label: 153 0.04\n",
      "Label: 154 0.0\n",
      "Label: 155 0.0\n",
      "Label: 156 0.0\n",
      "Label: 157 0.06\n",
      "Label: 158 0.0\n",
      "Label: 159 0.0\n",
      "Label: 160 0.0\n",
      "Label: 161 0.0\n",
      "Label: 162 0.0\n",
      "Label: 163 0.0\n",
      "Label: 164 0.0\n",
      "Label: 165 0.0\n",
      "Label: 166 0.0\n",
      "Label: 167 0.0\n",
      "Label: 168 0.0\n",
      "Label: 169 0.02\n",
      "Label: 170 0.0\n",
      "Label: 171 0.0\n",
      "Label: 172 0.02\n",
      "Label: 173 0.0\n",
      "Label: 174 0.04\n",
      "Label: 175 0.0\n",
      "Label: 176 0.0\n",
      "Label: 177 0.0\n",
      "Label: 178 0.0\n",
      "Label: 179 0.0\n",
      "Label: 180 0.0\n",
      "Label: 181 0.0\n",
      "Label: 182 0.0\n",
      "Label: 183 0.0\n",
      "Label: 184 0.0\n",
      "Label: 185 0.0\n",
      "Label: 186 0.0\n",
      "Label: 187 0.0\n",
      "Label: 188 0.0\n",
      "Label: 189 0.0\n",
      "Label: 190 0.1\n",
      "Label: 191 0.0\n",
      "Label: 192 0.0\n",
      "Label: 193 0.0\n",
      "Label: 194 0.0\n",
      "Label: 195 0.0\n",
      "Label: 196 0.0\n",
      "Label: 197 0.04\n",
      "Label: 198 0.0\n",
      "Label: 199 0.0\n",
      "Label: 200 0.02\n",
      "Label: 201 0.0\n",
      "Label: 202 0.0\n",
      "Label: 203 0.0\n",
      "Label: 204 0.0\n",
      "Label: 205 0.06\n",
      "Label: 206 0.02\n",
      "Label: 207 0.0\n",
      "Label: 208 0.0\n",
      "Label: 209 0.0\n",
      "Label: 210 0.0\n",
      "Label: 211 0.0\n",
      "Label: 212 0.0\n",
      "Label: 213 0.0\n",
      "Label: 214 0.02\n",
      "Label: 215 0.0\n",
      "Label: 216 0.02\n",
      "Label: 217 0.0\n",
      "Label: 218 0.0\n",
      "Label: 219 0.0\n",
      "Label: 220 0.0\n",
      "Label: 221 0.02\n",
      "Label: 222 0.0\n",
      "Label: 223 0.0\n",
      "Label: 224 0.04\n",
      "Label: 225 0.02\n",
      "Label: 226 0.0\n",
      "Label: 227 0.0\n",
      "Label: 228 0.0\n",
      "Label: 229 0.02\n",
      "Label: 230 0.02\n",
      "Label: 231 0.0\n",
      "Label: 232 0.0\n",
      "Label: 233 0.0\n",
      "Label: 234 0.0\n",
      "Label: 235 0.0\n",
      "Label: 236 0.0\n",
      "Label: 237 0.02\n",
      "Label: 238 0.0\n",
      "Label: 239 0.0\n",
      "Label: 240 0.0\n",
      "Label: 241 0.0\n",
      "Label: 242 0.0\n",
      "Label: 243 0.0\n",
      "Label: 244 0.14\n",
      "Label: 245 0.0\n",
      "Label: 246 0.0\n",
      "Label: 247 0.02\n",
      "Label: 248 0.0\n",
      "Label: 249 0.0\n",
      "Label: 250 0.0\n",
      "Label: 251 0.0\n",
      "Label: 252 0.04\n",
      "Label: 253 0.0\n",
      "Label: 254 0.0\n",
      "Label: 255 0.02\n",
      "Label: 256 0.04\n",
      "Label: 257 0.0\n",
      "Label: 258 0.04\n",
      "Label: 259 0.0\n",
      "Label: 260 0.0\n",
      "Label: 261 0.0\n",
      "Label: 262 0.0\n",
      "Label: 263 0.0\n",
      "Label: 264 0.0\n",
      "Label: 265 0.0\n",
      "Label: 266 0.0\n",
      "Label: 267 0.0\n",
      "Label: 268 0.02\n",
      "Label: 269 0.0\n",
      "Label: 270 0.0\n",
      "Label: 271 0.0\n",
      "Label: 272 0.0\n",
      "Label: 273 0.0\n",
      "Label: 274 0.02\n",
      "Label: 275 0.02\n",
      "Label: 276 0.0\n",
      "Label: 277 0.0\n",
      "Label: 278 0.0\n",
      "Label: 279 0.0\n",
      "Label: 280 0.0\n",
      "Label: 281 0.0\n",
      "Label: 282 0.0\n",
      "Label: 283 0.02\n",
      "Label: 284 0.0\n",
      "Label: 285 0.0\n",
      "Label: 286 0.0\n",
      "Label: 287 0.02\n",
      "Label: 288 0.0\n",
      "Label: 289 0.0\n",
      "Label: 290 0.0\n",
      "Label: 291 0.0\n",
      "Label: 292 0.0\n",
      "Label: 293 0.02\n",
      "Label: 294 0.0\n",
      "Label: 295 0.0\n",
      "Label: 296 0.0\n",
      "Label: 297 0.0\n",
      "Label: 298 0.0\n",
      "Label: 299 0.0\n",
      "Label: 300 0.02\n",
      "Label: 301 0.0\n",
      "Label: 302 0.12\n",
      "Label: 303 0.0\n",
      "Label: 304 0.02\n",
      "Label: 305 0.0\n",
      "Label: 306 0.02\n",
      "Label: 307 0.0\n",
      "Label: 308 0.0\n",
      "Label: 309 0.0\n",
      "Label: 310 0.0\n",
      "Label: 311 0.0\n",
      "Label: 312 0.0\n",
      "Label: 313 0.0\n",
      "Label: 314 0.02\n",
      "Label: 315 0.0\n",
      "Label: 316 0.0\n",
      "Label: 317 0.0\n",
      "Label: 318 0.0\n",
      "Label: 319 0.0\n",
      "Label: 320 0.04\n",
      "Label: 321 0.0\n",
      "Label: 322 0.0\n",
      "Label: 323 0.0\n",
      "Label: 324 0.04\n",
      "Label: 325 0.08\n",
      "Label: 326 0.02\n",
      "Label: 327 0.0\n",
      "Label: 328 0.0\n",
      "Label: 329 0.0\n",
      "Label: 330 0.0\n",
      "Label: 331 0.0\n",
      "Label: 332 0.14\n",
      "Label: 333 0.0\n",
      "Label: 334 0.0\n",
      "Label: 335 0.0\n",
      "Label: 336 0.0\n",
      "Label: 337 0.0\n",
      "Label: 338 0.0\n",
      "Label: 339 0.04\n",
      "Label: 340 0.0\n",
      "Label: 341 0.02\n",
      "Label: 342 0.0\n",
      "Label: 343 0.0\n",
      "Label: 344 0.0\n",
      "Label: 345 0.0\n",
      "Label: 346 0.0\n",
      "Label: 347 0.04\n",
      "Label: 348 0.0\n",
      "Label: 349 0.0\n",
      "Label: 350 0.0\n",
      "Label: 351 0.0\n",
      "Label: 352 0.0\n",
      "Label: 353 0.0\n",
      "Label: 354 0.0\n",
      "Label: 355 0.0\n",
      "Label: 356 0.0\n",
      "Label: 357 0.0\n",
      "Label: 358 0.0\n",
      "Label: 359 0.0\n",
      "Label: 360 0.0\n",
      "Label: 361 0.0\n",
      "Label: 362 0.02\n",
      "Label: 363 0.0\n",
      "Label: 364 0.0\n",
      "Label: 365 0.0\n",
      "Label: 366 0.02\n",
      "Label: 367 0.02\n",
      "Label: 368 0.0\n",
      "Label: 369 0.0\n",
      "Label: 370 0.0\n",
      "Label: 371 0.0\n",
      "Label: 372 0.02\n",
      "Label: 373 0.0\n",
      "Label: 374 0.0\n",
      "Label: 375 0.0\n",
      "Label: 376 0.0\n",
      "Label: 377 0.0\n",
      "Label: 378 0.0\n",
      "Label: 379 0.02\n",
      "Label: 380 0.0\n",
      "Label: 381 0.0\n",
      "Label: 382 0.0\n",
      "Label: 383 0.0\n",
      "Label: 384 0.0\n",
      "Label: 385 0.0\n",
      "Label: 386 0.0\n",
      "Label: 387 0.02\n",
      "Label: 388 0.06\n",
      "Label: 389 0.04\n",
      "Label: 390 0.0\n",
      "Label: 391 0.02\n",
      "Label: 392 0.0\n",
      "Label: 393 0.0\n",
      "Label: 394 0.02\n",
      "Label: 395 0.0\n",
      "Label: 396 0.0\n",
      "Label: 397 0.0\n",
      "Label: 398 0.0\n",
      "Label: 399 0.14\n",
      "Label: 400 0.02\n",
      "Label: 401 0.02\n",
      "Label: 402 0.0\n",
      "Label: 403 0.02\n",
      "Label: 404 0.1\n",
      "Label: 405 0.0\n",
      "Label: 406 0.0\n",
      "Label: 407 0.2\n",
      "Label: 408 0.0\n",
      "Label: 409 0.0\n",
      "Label: 410 0.0\n",
      "Label: 411 0.0\n",
      "Label: 412 0.0\n",
      "Label: 413 0.0\n",
      "Label: 414 0.06\n",
      "Label: 415 0.0\n",
      "Label: 416 0.0\n",
      "Label: 417 0.0\n",
      "Label: 418 0.0\n",
      "Label: 419 0.0\n",
      "Label: 420 0.0\n",
      "Label: 421 0.0\n",
      "Label: 422 0.0\n",
      "Label: 423 0.0\n",
      "Label: 424 0.0\n",
      "Label: 425 0.04\n",
      "Label: 426 0.0\n",
      "Label: 427 0.0\n",
      "Label: 428 0.0\n",
      "Label: 429 0.0\n",
      "Label: 430 0.08\n",
      "Label: 431 0.08\n",
      "Label: 432 0.0\n",
      "Label: 433 0.0\n",
      "Label: 434 0.0\n",
      "Label: 435 0.0\n",
      "Label: 436 0.0\n",
      "Label: 437 0.18\n",
      "Label: 438 0.0\n",
      "Label: 439 0.0\n",
      "Label: 440 0.0\n",
      "Label: 441 0.0\n",
      "Label: 442 0.0\n",
      "Label: 443 0.0\n",
      "Label: 444 0.0\n",
      "Label: 445 0.0\n",
      "Label: 446 0.06\n",
      "Label: 447 0.0\n",
      "Label: 448 0.0\n",
      "Label: 449 0.0\n",
      "Label: 450 0.0\n",
      "Label: 451 0.0\n",
      "Label: 452 0.0\n",
      "Label: 453 0.02\n",
      "Label: 454 0.0\n",
      "Label: 455 0.0\n",
      "Label: 456 0.0\n",
      "Label: 457 0.0\n",
      "Label: 458 0.0\n",
      "Label: 459 0.02\n",
      "Label: 460 0.06\n",
      "Label: 461 0.0\n",
      "Label: 462 0.0\n",
      "Label: 463 0.0\n",
      "Label: 464 0.0\n",
      "Label: 465 0.1\n",
      "Label: 466 0.08\n",
      "Label: 467 0.0\n",
      "Label: 468 0.0\n",
      "Label: 469 0.0\n",
      "Label: 470 0.0\n",
      "Label: 471 0.02\n",
      "Label: 472 0.18\n",
      "Label: 473 0.04\n",
      "Label: 474 0.0\n",
      "Label: 475 0.02\n",
      "Label: 476 0.0\n",
      "Label: 477 0.0\n",
      "Label: 478 0.0\n",
      "Label: 479 0.04\n",
      "Label: 480 0.0\n",
      "Label: 481 0.0\n",
      "Label: 482 0.12\n",
      "Label: 483 0.0\n",
      "Label: 484 0.08\n",
      "Label: 485 0.0\n",
      "Label: 486 0.02\n",
      "Label: 487 0.0\n",
      "Label: 488 0.0\n",
      "Label: 489 0.0\n",
      "Label: 490 0.0\n",
      "Label: 491 0.0\n",
      "Label: 492 0.0\n",
      "Label: 493 0.12\n",
      "Label: 494 0.0\n",
      "Label: 495 0.08\n",
      "Label: 496 0.0\n",
      "Label: 497 0.0\n",
      "Label: 498 0.0\n",
      "Label: 499 0.0\n",
      "Label: 500 0.0\n",
      "Label: 501 0.0\n",
      "Label: 502 0.0\n",
      "Label: 503 0.0\n",
      "Label: 504 0.0\n",
      "Label: 505 0.0\n",
      "Label: 506 0.0\n",
      "Label: 507 0.0\n",
      "Label: 508 0.02\n",
      "Label: 509 0.0\n",
      "Label: 510 0.12\n",
      "Label: 511 0.02\n",
      "Label: 512 0.0\n",
      "Label: 513 0.02\n",
      "Label: 514 0.0\n",
      "Label: 515 0.0\n",
      "Label: 516 0.0\n",
      "Label: 517 0.0\n",
      "Label: 518 0.04\n",
      "Label: 519 0.0\n",
      "Label: 520 0.0\n",
      "Label: 521 0.0\n",
      "Label: 522 0.0\n",
      "Label: 523 0.0\n",
      "Label: 524 0.02\n",
      "Label: 525 0.04\n",
      "Label: 526 0.0\n",
      "Label: 527 0.0\n",
      "Label: 528 0.0\n",
      "Label: 529 0.0\n",
      "Label: 530 0.0\n",
      "Label: 531 0.0\n",
      "Label: 532 0.0\n",
      "Label: 533 0.06\n",
      "Label: 534 0.0\n",
      "Label: 535 0.0\n",
      "Label: 536 0.0\n",
      "Label: 537 0.22\n",
      "Label: 538 0.0\n",
      "Label: 539 0.02\n",
      "Label: 540 0.1\n",
      "Label: 541 0.0\n",
      "Label: 542 0.0\n",
      "Label: 543 0.0\n",
      "Label: 544 0.02\n",
      "Label: 545 0.0\n",
      "Label: 546 0.02\n",
      "Label: 547 0.06\n",
      "Label: 548 0.02\n",
      "Label: 549 0.06\n",
      "Label: 550 0.14\n",
      "Label: 551 0.04\n",
      "Label: 552 0.0\n",
      "Label: 553 0.0\n",
      "Label: 554 0.0\n",
      "Label: 555 0.02\n",
      "Label: 556 0.0\n",
      "Label: 557 0.0\n",
      "Label: 558 0.0\n",
      "Label: 559 0.0\n",
      "Label: 560 0.0\n",
      "Label: 561 0.0\n",
      "Label: 562 0.02\n",
      "Label: 563 0.0\n",
      "Label: 564 0.02\n",
      "Label: 565 0.14\n",
      "Label: 566 0.0\n",
      "Label: 567 0.0\n",
      "Label: 568 0.0\n",
      "Label: 569 0.0\n",
      "Label: 570 0.0\n",
      "Label: 571 0.0\n",
      "Label: 572 0.0\n",
      "Label: 573 0.0\n",
      "Label: 574 0.0\n",
      "Label: 575 0.0\n",
      "Label: 576 0.0\n",
      "Label: 577 0.0\n",
      "Label: 578 0.02\n",
      "Label: 579 0.02\n",
      "Label: 580 0.0\n",
      "Label: 581 0.02\n",
      "Label: 582 0.0\n",
      "Label: 583 0.0\n",
      "Label: 584 0.0\n",
      "Label: 585 0.0\n",
      "Label: 586 0.06\n",
      "Label: 587 0.0\n",
      "Label: 588 0.0\n",
      "Label: 589 0.0\n",
      "Label: 590 0.0\n",
      "Label: 591 0.14\n",
      "Label: 592 0.0\n",
      "Label: 593 0.0\n",
      "Label: 594 0.0\n",
      "Label: 595 0.04\n",
      "Label: 596 0.0\n",
      "Label: 597 0.04\n",
      "Label: 598 0.02\n",
      "Label: 599 0.0\n",
      "Label: 600 0.0\n",
      "Label: 601 0.08\n",
      "Label: 602 0.0\n",
      "Label: 603 0.02\n",
      "Label: 604 0.02\n",
      "Label: 605 0.0\n",
      "Label: 606 0.0\n",
      "Label: 607 0.38\n",
      "Label: 608 0.0\n",
      "Label: 609 0.0\n",
      "Label: 610 0.04\n",
      "Label: 611 0.06\n",
      "Label: 612 0.0\n",
      "Label: 613 0.0\n",
      "Label: 614 0.0\n",
      "Label: 615 0.02\n",
      "Label: 616 0.0\n",
      "Label: 617 0.0\n",
      "Label: 618 0.0\n",
      "Label: 619 0.02\n",
      "Label: 620 0.0\n",
      "Label: 621 0.0\n",
      "Label: 622 0.0\n",
      "Label: 623 0.0\n",
      "Label: 624 0.0\n",
      "Label: 625 0.04\n",
      "Label: 626 0.02\n",
      "Label: 627 0.0\n",
      "Label: 628 0.04\n",
      "Label: 629 0.0\n",
      "Label: 630 0.0\n",
      "Label: 631 0.0\n",
      "Label: 632 0.02\n",
      "Label: 633 0.0\n",
      "Label: 634 0.0\n",
      "Label: 635 0.0\n",
      "Label: 636 0.08\n",
      "Label: 637 0.0\n",
      "Label: 638 0.0\n",
      "Label: 639 0.0\n",
      "Label: 640 0.02\n",
      "Label: 641 0.0\n",
      "Label: 642 0.0\n",
      "Label: 643 0.0\n",
      "Label: 644 0.0\n",
      "Label: 645 0.0\n",
      "Label: 646 0.0\n",
      "Label: 647 0.0\n",
      "Label: 648 0.0\n",
      "Label: 649 0.04\n",
      "Label: 650 0.0\n",
      "Label: 651 0.0\n",
      "Label: 652 0.0\n",
      "Label: 653 0.0\n",
      "Label: 654 0.1\n",
      "Label: 655 0.0\n",
      "Label: 656 0.0\n",
      "Label: 657 0.0\n",
      "Label: 658 0.0\n",
      "Label: 659 0.0\n",
      "Label: 660 0.0\n",
      "Label: 661 0.0\n",
      "Label: 662 0.0\n",
      "Label: 663 0.0\n",
      "Label: 664 0.0\n",
      "Label: 665 0.0\n",
      "Label: 666 0.0\n",
      "Label: 667 0.02\n",
      "Label: 668 0.0\n",
      "Label: 669 0.06\n",
      "Label: 670 0.0\n",
      "Label: 671 0.0\n",
      "Label: 672 0.0\n",
      "Label: 673 0.0\n",
      "Label: 674 0.0\n",
      "Label: 675 0.0\n",
      "Label: 676 0.0\n",
      "Label: 677 0.0\n",
      "Label: 678 0.0\n",
      "Label: 679 0.04\n",
      "Label: 680 0.0\n",
      "Label: 681 0.0\n",
      "Label: 682 0.04\n",
      "Label: 683 0.0\n",
      "Label: 684 0.02\n",
      "Label: 685 0.02\n",
      "Label: 686 0.0\n",
      "Label: 687 0.02\n",
      "Label: 688 0.0\n",
      "Label: 689 0.0\n",
      "Label: 690 0.04\n",
      "Label: 691 0.0\n",
      "Label: 692 0.0\n",
      "Label: 693 0.0\n",
      "Label: 694 0.0\n",
      "Label: 695 0.0\n",
      "Label: 696 0.0\n",
      "Label: 697 0.0\n",
      "Label: 698 0.0\n",
      "Label: 699 0.0\n",
      "Label: 700 0.0\n",
      "Label: 701 0.12\n",
      "Label: 702 0.0\n",
      "Label: 703 0.0\n",
      "Label: 704 0.0\n",
      "Label: 705 0.0\n",
      "Label: 706 0.04\n",
      "Label: 707 0.0\n",
      "Label: 708 0.0\n",
      "Label: 709 0.0\n",
      "Label: 710 0.0\n",
      "Label: 711 0.0\n",
      "Label: 712 0.0\n",
      "Label: 713 0.0\n",
      "Label: 714 0.0\n",
      "Label: 715 0.02\n",
      "Label: 716 0.0\n",
      "Label: 717 0.0\n",
      "Label: 718 0.02\n",
      "Label: 719 0.02\n",
      "Label: 720 0.0\n",
      "Label: 721 0.0\n",
      "Label: 722 0.0\n",
      "Label: 723 0.0\n",
      "Label: 724 0.0\n",
      "Label: 725 0.0\n",
      "Label: 726 0.04\n",
      "Label: 727 0.0\n",
      "Label: 728 0.0\n",
      "Label: 729 0.0\n",
      "Label: 730 0.0\n",
      "Label: 731 0.0\n",
      "Label: 732 0.0\n",
      "Label: 733 0.0\n",
      "Label: 734 0.08\n",
      "Label: 735 0.0\n",
      "Label: 736 0.0\n",
      "Label: 737 0.0\n",
      "Label: 738 0.0\n",
      "Label: 739 0.0\n",
      "Label: 740 0.0\n",
      "Label: 741 0.08\n",
      "Label: 742 0.0\n",
      "Label: 743 0.0\n",
      "Label: 744 0.0\n",
      "Label: 745 0.0\n",
      "Label: 746 0.0\n",
      "Label: 747 0.0\n",
      "Label: 748 0.0\n",
      "Label: 749 0.0\n",
      "Label: 750 0.0\n",
      "Label: 751 0.0\n",
      "Label: 752 0.0\n",
      "Label: 753 0.0\n",
      "Label: 754 0.0\n",
      "Label: 755 0.1\n",
      "Label: 756 0.0\n",
      "Label: 757 0.06\n",
      "Label: 758 0.0\n",
      "Label: 759 0.02\n",
      "Label: 760 0.02\n",
      "Label: 761 0.0\n",
      "Label: 762 0.0\n",
      "Label: 763 0.04\n",
      "Label: 764 0.0\n",
      "Label: 765 0.0\n",
      "Label: 766 0.0\n",
      "Label: 767 0.0\n",
      "Label: 768 0.0\n",
      "Label: 769 0.0\n",
      "Label: 770 0.0\n",
      "Label: 771 0.0\n",
      "Label: 772 0.0\n",
      "Label: 773 0.0\n",
      "Label: 774 0.0\n",
      "Label: 775 0.0\n",
      "Label: 776 0.06\n",
      "Label: 777 0.0\n",
      "Label: 778 0.0\n",
      "Label: 779 0.0\n",
      "Label: 780 0.14\n",
      "Label: 781 0.0\n",
      "Label: 782 0.08\n",
      "Label: 783 0.0\n",
      "Label: 784 0.0\n",
      "Label: 785 0.0\n",
      "Label: 786 0.0\n",
      "Label: 787 0.0\n",
      "Label: 788 0.0\n",
      "Label: 789 0.0\n",
      "Label: 790 0.0\n",
      "Label: 791 0.0\n",
      "Label: 792 0.0\n",
      "Label: 793 0.0\n",
      "Label: 794 0.06\n",
      "Label: 795 0.04\n",
      "Label: 796 0.02\n",
      "Label: 797 0.0\n",
      "Label: 798 0.06\n",
      "Label: 799 0.0\n",
      "Label: 800 0.02\n",
      "Label: 801 0.0\n",
      "Label: 802 0.06\n",
      "Label: 803 0.02\n",
      "Label: 804 0.0\n",
      "Label: 805 0.0\n",
      "Label: 806 0.0\n",
      "Label: 807 0.0\n",
      "Label: 808 0.0\n",
      "Label: 809 0.0\n",
      "Label: 810 0.0\n",
      "Label: 811 0.0\n",
      "Label: 812 0.0\n",
      "Label: 813 0.0\n",
      "Label: 814 0.0\n",
      "Label: 815 0.0\n",
      "Label: 816 0.0\n",
      "Label: 817 0.06\n",
      "Label: 818 0.0\n",
      "Label: 819 0.04\n",
      "Label: 820 0.16\n",
      "Label: 821 0.02\n",
      "Label: 822 0.0\n",
      "Label: 823 0.02\n",
      "Label: 824 0.0\n",
      "Label: 825 0.0\n",
      "Label: 826 0.0\n",
      "Label: 827 0.0\n",
      "Label: 828 0.0\n",
      "Label: 829 0.0\n",
      "Label: 830 0.0\n",
      "Label: 831 0.0\n",
      "Label: 832 0.0\n",
      "Label: 833 0.04\n",
      "Label: 834 0.0\n",
      "Label: 835 0.0\n",
      "Label: 836 0.0\n",
      "Label: 837 0.0\n",
      "Label: 838 0.0\n",
      "Label: 839 0.0\n",
      "Label: 840 0.0\n",
      "Label: 841 0.0\n",
      "Label: 842 0.0\n",
      "Label: 843 0.02\n",
      "Label: 844 0.0\n",
      "Label: 845 0.0\n",
      "Label: 846 0.02\n",
      "Label: 847 0.04\n",
      "Label: 848 0.0\n",
      "Label: 849 0.0\n",
      "Label: 850 0.0\n",
      "Label: 851 0.0\n",
      "Label: 852 0.0\n",
      "Label: 853 0.0\n",
      "Label: 854 0.0\n",
      "Label: 855 0.0\n",
      "Label: 856 0.0\n",
      "Label: 857 0.0\n",
      "Label: 858 0.0\n",
      "Label: 859 0.0\n",
      "Label: 860 0.0\n",
      "Label: 861 0.02\n",
      "Label: 862 0.0\n",
      "Label: 863 0.0\n",
      "Label: 864 0.0\n",
      "Label: 865 0.0\n",
      "Label: 866 0.0\n",
      "Label: 867 0.0\n",
      "Label: 868 0.0\n",
      "Label: 869 0.0\n",
      "Label: 870 0.0\n",
      "Label: 871 0.02\n",
      "Label: 872 0.0\n",
      "Label: 873 0.0\n",
      "Label: 874 0.04\n",
      "Label: 875 0.0\n",
      "Label: 876 0.02\n",
      "Label: 877 0.0\n",
      "Label: 878 0.0\n",
      "Label: 879 0.0\n",
      "Label: 880 0.0\n",
      "Label: 881 0.04\n",
      "Label: 882 0.0\n",
      "Label: 883 0.02\n",
      "Label: 884 0.0\n",
      "Label: 885 0.0\n",
      "Label: 886 0.0\n",
      "Label: 887 0.0\n",
      "Label: 888 0.04\n",
      "Label: 889 0.0\n",
      "Label: 890 0.0\n",
      "Label: 891 0.0\n",
      "Label: 892 0.02\n",
      "Label: 893 0.0\n",
      "Label: 894 0.02\n",
      "Label: 895 0.08\n",
      "Label: 896 0.0\n",
      "Label: 897 0.0\n",
      "Label: 898 0.0\n",
      "Label: 899 0.0\n",
      "Label: 900 0.02\n",
      "Label: 901 0.06\n",
      "Label: 902 0.0\n",
      "Label: 903 0.0\n",
      "Label: 904 0.0\n",
      "Label: 905 0.0\n",
      "Label: 906 0.0\n",
      "Label: 907 0.0\n",
      "Label: 908 0.04\n",
      "Label: 909 0.0\n",
      "Label: 910 0.0\n",
      "Label: 911 0.0\n",
      "Label: 912 0.0\n",
      "Label: 913 0.0\n",
      "Label: 914 0.0\n",
      "Label: 915 0.0\n",
      "Label: 916 0.1\n",
      "Label: 917 0.0\n",
      "Label: 918 0.0\n",
      "Label: 919 0.0\n",
      "Label: 920 0.0\n",
      "Label: 921 0.0\n",
      "Label: 922 0.04\n",
      "Label: 923 0.04\n",
      "Label: 924 0.0\n",
      "Label: 925 0.08\n",
      "Label: 926 0.0\n",
      "Label: 927 0.02\n",
      "Label: 928 0.0\n",
      "Label: 929 0.0\n",
      "Label: 930 0.0\n",
      "Label: 931 0.0\n",
      "Label: 932 0.0\n",
      "Label: 933 0.06\n",
      "Label: 934 0.0\n",
      "Label: 935 0.0\n",
      "Label: 936 0.0\n",
      "Label: 937 0.0\n",
      "Label: 938 0.0\n",
      "Label: 939 0.0\n",
      "Label: 940 0.02\n",
      "Label: 941 0.0\n",
      "Label: 942 0.0\n",
      "Label: 943 0.0\n",
      "Label: 944 0.0\n",
      "Label: 945 0.0\n",
      "Label: 946 0.02\n",
      "Label: 947 0.0\n",
      "Label: 948 0.0\n",
      "Label: 949 0.0\n",
      "Label: 950 0.0\n",
      "Label: 951 0.0\n",
      "Label: 952 0.0\n",
      "Label: 953 0.0\n",
      "Label: 954 0.0\n",
      "Label: 955 0.0\n",
      "Label: 956 0.0\n",
      "Label: 957 0.0\n",
      "Label: 958 0.02\n",
      "Label: 959 0.02\n",
      "Label: 960 0.0\n",
      "Label: 961 0.0\n",
      "Label: 962 0.0\n",
      "Label: 963 0.04\n",
      "Label: 964 0.0\n",
      "Label: 965 0.0\n",
      "Label: 966 0.0\n",
      "Label: 967 0.0\n",
      "Label: 968 0.0\n",
      "Label: 969 0.0\n",
      "Label: 970 0.02\n",
      "Label: 971 0.0\n",
      "Label: 972 0.0\n",
      "Label: 973 0.0\n",
      "Label: 974 0.08\n",
      "Label: 975 0.02\n",
      "Label: 976 0.1\n",
      "Label: 977 0.06\n",
      "Label: 978 0.0\n",
      "Label: 979 0.28\n",
      "Label: 980 0.24\n",
      "Label: 981 0.0\n",
      "Label: 982 0.02\n",
      "Label: 983 0.02\n",
      "Label: 984 0.0\n",
      "Label: 985 0.14\n",
      "Label: 986 0.08\n",
      "Label: 987 0.0\n",
      "Label: 988 0.0\n",
      "Label: 989 0.0\n",
      "Label: 990 0.0\n",
      "Label: 991 0.0\n",
      "Label: 992 0.06\n",
      "Label: 993 0.0\n",
      "Label: 994 0.0\n",
      "Label: 995 0.1\n",
      "Label: 996 0.0\n",
      "Label: 997 0.02\n",
      "Label: 998 0.0\n",
      "Label: 999 0.02\n"
     ]
    }
   ],
   "source": [
    "classes = [0] * 1000\n",
    "classesCnt = [0] * 1000\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == y_test[i]:\n",
    "        classes[pred[i]] += 1\n",
    "    classesCnt[y_test[i]] += 1\n",
    "    \n",
    "for i in range(1000):\n",
    "    print(\"Label:\", i, classes[i]/classesCnt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39bac937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01204\n"
     ]
    }
   ],
   "source": [
    "classes = np.array(classes)\n",
    "print(np.sum(classes)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69202b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f772f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe991a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchKernel",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
